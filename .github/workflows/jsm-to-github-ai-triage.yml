name: "JSM → GitHub Issue + AI Triage (SLA label + Copilot link + safe grep)"

on:
  repository_dispatch:
    types: [jsm_ticket_created]
  workflow_dispatch:
    inputs:
      issue_key:
        description: "JSM key (e.g. SD-1)"
        required: false
        type: string

concurrency:
  group: jsm-${{ github.event.client_payload.issue_key || github.event.inputs.issue_key || 'manual' }}
  cancel-in-progress: false

permissions:
  contents: read
  issues: write
  models: read

env:
  TZ: America/Mexico_City
  JIRA_BASE_URL: https://appix.atlassian.net

jobs:
  triage:
    runs-on: ubuntu-latest
    timeout-minutes: 22

    steps:
      - name: Checkout (read-only)
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          fetch-depth: 1

      - name: Resolve issue key
        id: key
        run: |
          set -euo pipefail
          if [ -n "${{ github.event.client_payload.issue_key }}" ]; then
            echo "issue_key=${{ github.event.client_payload.issue_key }}" >> "$GITHUB_OUTPUT"
          elif [ -n "${{ github.event.inputs.issue_key }}" ]; then
            echo "issue_key=${{ github.event.inputs.issue_key }}" >> "$GITHUB_OUTPUT"
          else
            echo "Falta issue_key"; exit 1
          fi

      - name: Read JSM ticket
        id: jsm
        env:
          JIRA_EMAIL: ${{ secrets.JIRA_EMAIL }}
          JIRA_API_TOKEN: ${{ secrets.JIRA_API_TOKEN }}
          ISSUE_KEY: ${{ steps.key.outputs.issue_key }}
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y jq
          AUTH="$(printf "%s:%s" "$JIRA_EMAIL" "$JIRA_API_TOKEN" | base64 -w 0 2>/dev/null || printf "%s:%s" "$JIRA_EMAIL" "$JIRA_API_TOKEN" | base64)"
          curl -fsS -H "Authorization: Basic $AUTH" -H "Accept: application/json" \
            "$JIRA_BASE_URL/rest/api/3/issue/$ISSUE_KEY?expand=renderedFields&fields=summary,description,priority,reporter,attachment,issuetype,project" \
            > issue.json
          jq -re '.fields' issue.json >/dev/null
          jq -r '.renderedFields.description // ""' issue.json > description.html
          jq -r '.fields.attachment // [] | .[] | [.filename,.content,.mimeType] | @tsv' issue.json > attachments.tsv || true
          {
            echo "summary=$(jq -r '.fields.summary' issue.json)"
            echo "priority=$(jq -r '.fields.priority.name // \"Unspecified\"' issue.json)"
            echo "reporter=$(jq -r '.fields.reporter.displayName // \"Unknown\"' issue.json)"
            echo "project=$(jq -r '.fields.project.key' issue.json)"
            echo "type=$(jq -r '.fields.issuetype.name' issue.json)"
          } >> "$GITHUB_OUTPUT"

      - name: Normalize JSM description (absolute links, no inline img)
        run: |
          set -euo pipefail
          sed -E "s#(src|href)=\"\/#\\1=\"${JIRA_BASE_URL}/#g" description.html > description_abs.html
          perl -0777 -pe 's#<img[^>]+src="([^"]+)"[^>]*>#\[Imagen JSM\]\($1\)#gi' description_abs.html > description_fixed.html

      - name: Install tools
        run: |
          sudo apt-get update -y
          sudo apt-get install -y dnsutils tesseract-ocr jq

      - name: Download image attachments + OCR
        id: ocr
        env:
          JIRA_EMAIL: ${{ secrets.JIRA_EMAIL }}
          JIRA_API_TOKEN: ${{ secrets.JIRA_API_TOKEN }}
        run: |
          set -euo pipefail
          AUTH="$(printf "%s:%s" "$JIRA_EMAIL" "$JIRA_API_TOKEN" | base64 -w 0 2>/dev/null || printf "%s:%s" "$JIRA_EMAIL" "$JIRA_API_TOKEN" | base64)"
          mkdir -p attachments ocr
          : > ocr/ocr.txt
          if [ -s attachments.tsv ]; then
            while IFS=$'\t' read -r NAME URL MIME; do
              case "$MIME" in
                image/*)
                  OUT="attachments/${NAME}"
                  curl -fsS -H "Authorization: Basic $AUTH" -o "$OUT" "$URL" || continue
                  tesseract "$OUT" "ocr/${NAME}" -l spa+eng --psm 6 >/dev/null 2>&1 || true
                  if [ -f "ocr/${NAME}.txt" ]; then
                    printf "%s\n" "--- ${NAME} ---" >> ocr/ocr.txt
                    cat "ocr/${NAME}.txt" >> ocr/ocr.txt
                    printf "\n" >> ocr/ocr.txt
                  fi
                  ;;
              esac
            done < attachments.tsv
          fi
          [ -s ocr/ocr.txt ] || echo "No OCR text" > ocr/ocr.txt
          echo "ocr_file=ocr/ocr.txt" >> "$GITHUB_OUTPUT"

      - name: Detect hostname (vars/desc/OCR/repo)
        id: host
        env:
          SITE_URL_VAR: ${{ vars.SITE_URL }}
        run: |
          set -euo pipefail
          pick=""
          [ -n "${SITE_URL_VAR:-}" ] && pick="$SITE_URL_VAR"
          [ -z "$pick" ] && pick="$(grep -RhoE 'https?://[a-zA-Z0-9.-]+\.[a-z]{2,}[^\" ]*' --include='*.{ts,tsx,js,jsx,json,md,astro,php,html}' -m1 || true)"
          [ -z "$pick" ] && pick="$(grep -Eo 'https?://[^ )"]+' -m1 description_fixed.html || true)"
          [ -z "$pick" ] && pick="$(grep -Eo 'https?://[^ ]+' -m1 ocr/ocr.txt || true)"
          host="$(echo "$pick" | sed -E 's#https?://##; s#/.*##; s/[^a-zA-Z0-9\.\-].*//')"
          [ -z "$host" ] && host="localhost"
          echo "host=$host" >> "$GITHUB_OUTPUT"
          echo "url_guess=$pick" >> "$GITHUB_OUTPUT"

      - name: Network diagnostics (DNS/TLS/HTTP) - safe
        id: net
        run: |
          set -euo pipefail
          HOST="${{ steps.host.outputs.host }}"
          : > netdiag.md
          echo "## Network diagnostics for $HOST" >> netdiag.md
          echo "### DNS" >> netdiag.md
          { dig +short A "$HOST"; dig +short AAAA "$HOST"; } | sed 's/^/- /' >> netdiag.md || true
          echo -e "\n### TLS (dates, issuer, subject)" >> netdiag.md
          timeout 10 bash -lc 'echo | openssl s_client -servername "$HOST" -connect "$HOST:443" 2>/dev/null | openssl x509 -noout -dates -issuer -subject' \
            | sed 's/^/  /' >> netdiag.md || echo "  (TLS check failed)" >> netdiag.md
          echo -e "\n### HTTP HEAD timings" >> netdiag.md
          curl -I --silent --show-error --connect-timeout 8 --max-time 15 "https://$HOST/" \
            -w "\ncode:%{http_code} ip:%{remote_ip} t_connect:%{time_connect}s t_ttfb:%{time_starttransfer}s\n" \
            -o >(tee headers.txt >/dev/null) >> netdiag.md || echo "Request failed (timeout/conn error)" >> netdiag.md
          if [ -f headers.txt ]; then
            echo -e "\n### Response headers (subset)" >> netdiag.md
            grep -Ei '^(server:|cf-|x-litespeed|x-cache|via:|date:|content-type:|strict-transport-security:)' headers.txt | sed 's/^/  /' >> netdiag.md || true
          fi

      - name: Build attachment list (JSM links)
        run: |
          set -euo pipefail
          if [ -s attachments.tsv ]; then
            while IFS=$'\t' read -r NAME URL MIME; do
              printf -- "- [%s](%s)\n" "$NAME" "$URL"
            done < attachments.tsv > attachments.md
          else
            printf "_Sin adjuntos_\n" > attachments.md
          fi

      - name: Repo context (tree + matches + TZ signals)  # <-- sin pipes que rompan
        id: repocontext
        env:
          SUMMARY: ${{ steps.jsm.outputs.summary }}
        run: |
          set -euo pipefail
          PLAIN_DESC="$(sed -E 's/<[^>]+>//g' description_fixed.html | tr -d '\r')"
          TOKENS="$(printf "%s\n%s\n" "${SUMMARY:-}" "${PLAIN_DESC:-}" | tr '[:upper:]' '[:lower:]' | tr -cs '[:alnum:]' '\n' | awk 'length>2' | sort -u | head -n 20 | paste -sd'|' -)"
          [ -n "$TOKENS" ] || TOKENS="."
          echo "### Repo tree (top 200)" > repo_context.md
          (git ls-files 2>/dev/null || find . -type f) | head -n 200 >> repo_context.md

          echo "" >> repo_context.md
          echo "### Keyword pattern" >> repo_context.md
          echo "$TOKENS" >> repo_context.md
          echo "" >> repo_context.md
          echo "### Matches (first 200 lines across source files)" >> repo_context.md
          # Genera archivo y luego trunca, evitando pipe con head
          : > _matches.txt
          find . -type d \( -name .git -o -name node_modules -o -name dist -o -name build \) -prune -o \
            -type f \( -name "*.py" -o -name "*.js" -o -name "*.ts" -o -name "*.tsx" -o -name "*.jsx" -o -name "*.php" -o -name "*.html" -o -name "*.astro" -o -name "*.css" -o -name "*.scss" -o -name "*.vue" -o -name "*.json" -o -name "*.md" \) \
            -print0 | xargs -0 -I{} sh -c 'grep -n -i -E "$0" -m 2 "{}" 2>/dev/null || true' "$TOKENS" >> _matches.txt || true
          sed -n '1,200p' _matches.txt >> repo_context.md || true

          echo "" >> repo_context.md
          echo "### TZ / daily-unique signals" >> repo_context.md
          grep -RniE 'TIME_ZONE|USE_TZ|date_trunc|timezone\(|AT TIME ZONE|unique.*day|daily|per.?day' \
            --include='*.py' --include='*.sql' --include='*.js' --include='*.ts' 2>/dev/null > _tz_hits.txt || true
          sed -n '1,80p' _tz_hits.txt >> repo_context.md || true

          if [ -f package.json ]; then
            echo "" >> repo_context.md
            echo "### Project commands" >> repo_context.md
            echo "\`\`\`json" >> repo_context.md
            jq -r '.scripts // {}' package.json >> repo_context.md
            echo "\`\`\`" >> repo_context.md
          fi

      - name: Prepare prompt (OCR + NetDiag + repo)
        id: prep
        run: |
          set -euo pipefail
          printf "%s\n" "### Descripcion (HTML)" > prompt.md
          cat description_fixed.html >> prompt.md
          printf "\n%s\n" "### OCR de imagenes" >> prompt.md
          cat ocr/ocr.txt >> prompt.md
          printf "\n%s\n" "### Network diagnostics" >> prompt.md
          cat netdiag.md >> prompt.md 2>/dev/null || true
          printf "\n%s\n" "### Repo context" >> prompt.md
          cat repo_context.md >> prompt.md
          printf "\n%s\n" "### Labels permitidas" >> prompt.md
          echo "bug, documentation, duplicate, enhancement, good first issue, help wanted, invalid, question, wontfix" >> prompt.md

      - name: AI analysis (core MD only; requirements/recs via JSON) + TZ/day-boundary hints
        id: ai
        uses: actions/ai-inference@v1
        with:
          model: openai/gpt-4o-mini
          system-prompt: |
            Ingeniero de soporte senior. Usa el contexto (descripcion JSM, OCR, NetDiag, repo).
            En el MARKDOWN SOLO incluye:
            ## Clasificacion por capa
            - Capa sospechosa: (Cliente/Red | DNS/CDN | WAF/Seguridad | Servidor/Hosting | Aplicacion/Codigo)
            - Evidencia clave (max 5 bullets)
            - Confianza (baja/media/alta)
            ## Posible causa
            ## Solucion potencial
            ## Riesgos/Infra (WAF/VPN/Server)
            NO incluyas "Requisitos..." ni "Recomendaciones" en Markdown.
            Al final, bloque ```json``` con:
            {"layer":"Cliente/Red|DNS/CDN|WAF/Seguridad|Servidor/Hosting|Aplicacion/Codigo","cause":"...","solution":"...","replication_requirements_user":["..."],"replication_requirements_it":["..."],"recommendations_user":["..."],"recommendations_it":["..."],"risk_notes":"...","labels":["bug","question"],"confidence":"baja|media|alta"}
            Hints (no imprimir):
            - Reglas de registros únicos por día y zonas horarias: TIME_ZONE/USE_TZ de Django, Date en JS, tz de servidor/DB (date_trunc/AT TIME ZONE), caches/sesiones/cron.
            - Un único usuario afectado puede apuntar a estado de cliente/cuenta, horario local, reloj, cookies.
            Reglas:
            - Si hay ERR_CONNECTION_TIMED_OUT/NAME_NOT_RESOLVED o NetDiag evidencia DNS/TLS/timeout, prioriza Cliente/Red, DNS/CDN o WAF/Seguridad.
            - No inventes datos; pide lo mínimo necesario en los arreglos del JSON.
          prompt-file: prompt.md
          max-tokens: 1000

      - name: Parse AI JSON
        id: parse_ai
        run: |
          set -euo pipefail
          awk '/```json/{flag=1;next}/```/{flag=0}flag' "${{ steps.ai.outputs.response-file }}" > ai.json || true
          jq -e . ai.json >/dev/null 2>&1 || echo '{}' > ai.json
          echo "json=$(cat ai.json | jq -c .)" >> "$GITHUB_OUTPUT"

      - name: Sanitize AI Markdown (remove JSON + accidental sections)
        id: sanitize_ai
        run: |
          set -euo pipefail
          awk '
            /^```json$/ {injson=1; next}
            injson && /^```/ {injson=0; next}
            injson {next}
            /^## Requisitos/ {skip=1; next}
            /^## Recomendaciones/ {skip=1; next}
            skip && /^## / {skip=0}
            skip {next}
            {print}
          ' "${{ steps.ai.outputs.response-file }}" > ai_core.md
          echo "ai_core=ai_core.md" >> "$GITHUB_OUTPUT"

      - name: Build checklists (Requisitos y Recomendaciones)
        id: ck
        run: |
          set -euo pipefail
          jq -r '.replication_requirements_user // [] | .[] | "- [ ] " + .' ai.json > user_req_ck.md || true
          jq -r '.replication_requirements_it   // [] | .[] | "- [ ] " + .' ai.json > it_req_ck.md   || true
          jq -r '.recommendations_user // [] | .[] | "- [ ] " + .' ai.json > user_rec_ck.md || true
          jq -r '.recommendations_it   // [] | .[] | "- [ ] " + .' ai.json > it_rec_ck.md   || true
          [ -s user_req_ck.md ] || printf "%s\n" "- [ ] Screenshot de pantalla completa (incluye barra de direcciones y hora)" > user_req_ck.md
          [ -s it_req_ck.md   ] || printf "%s\n" "- [ ] Confirmar si hay mantenimiento/cambios en servidor, WAF o DNS" > it_req_ck.md
          [ -s user_rec_ck.md ] || printf "%s\n" "- [ ] Probar modo incógnito, otro navegador y sin VPN/Proxy" > user_rec_ck.md
          [ -s it_rec_ck.md   ] || printf "%s\n" "- [ ] Revisar logs del servidor y WAF/ModSecurity; validar TLS/DNS" > it_rec_ck.md

      - name: Fetch SLA from JSM (official API)
        id: sla
        env:
          JIRA_EMAIL: ${{ secrets.JIRA_EMAIL }}
          JIRA_API_TOKEN: ${{ secrets.JIRA_API_TOKEN }}
          ISSUE_KEY: ${{ steps.key.outputs.issue_key }}
        run: |
          set -euo pipefail
          AUTH="$(printf "%s:%s" "$JIRA_EMAIL" "$JIRA_API_TOKEN" | base64 -w 0 2>/dev/null || printf "%s:%s" "$JIRA_EMAIL" "$JIRA_API_TOKEN" | base64)"
          curl -fsS -H "Authorization: Basic $AUTH" -H "Accept: application/json" \
            "$JIRA_BASE_URL/rest/servicedeskapi/request/${ISSUE_KEY}/sla" > sla.json
          : > sla.md
          echo "## SLA (JSM)" >> sla.md
          jq -r '
            .values[]? as $v
            | $v.name as $name
            | ( ($v.ongoingCycle // empty) as $o
                | if $o != null then
                    [ $name,
                      ($o.goalDuration.friendly // ($o.goalDuration.millis|tostring)+"ms"),
                      ($o.remainingTime.friendly // "n/a"),
                      ($o.breached // false)
                    ] | @tsv
                  else
                    ( ($v.completedCycles | last) as $c
                      | [ $name,
                          ($c.goalDuration.friendly // ($c.goalDuration.millis|tostring)+"ms"),
                          "completed",
                          ($c.breached // false)
                        ] | @tsv )
                  end )' sla.json \
          > _sla_lines.tsv || true
          if [ -s _sla_lines.tsv ]; then
            while IFS=$'\t' read -r NAME GOAL REMAIN BREACHED; do
              [ -n "$NAME" ] || continue
              printf -- "- **%s** → Objetivo: %s · Restante/Estado: %s · Breach: %s\n" "$NAME" "$GOAL" "$REMAIN" "$BREACHED" >> sla.md
            done < _sla_lines.tsv
          fi
          if ! grep -q '^- ' sla.md; then
            echo "_No hay métricas de SLA disponibles para este ticket (o falta permiso de agente)_" >> sla.md
          fi

      - name: Derive SLA severity label (sev:P1|P2|P3) from JSM priority
        id: sev
        env:
          PRIORITY: ${{ steps.jsm.outputs.priority }}
        run: |
          set -euo pipefail
          PRI="$(echo "${PRIORITY:-}" | tr '[:lower:]' '[:upper:]')"
          if echo "$PRI" | grep -Eq 'CRIT|P1|URG|ALTA'; then
            echo "label=sev:P1" >> "$GITHUB_OUTPUT"
          elif echo "$PRI" | grep -Eq 'MED|P2|HIGH'; then
            echo "label=sev:P2" >> "$GITHUB_OUTPUT"
          else
            echo "label=sev:P3" >> "$GITHUB_OUTPUT"
          fi

      - name: Create Issue (IA limpia + Requisitos + Recomendaciones + SLA) + Labels IA + SLA
        id: create_issue
        uses: actions/github-script@v7
        env:
          ISSUE_KEY:     ${{ steps.key.outputs.issue_key }}
          SUMMARY:       ${{ steps.jsm.outputs.summary }}
          PROJECT:       ${{ steps.jsm.outputs.project }}
          TYPE:          ${{ steps.jsm.outputs.type }}
          PRIORITY:      ${{ steps.jsm.outputs.priority }}
          REPORTER:      ${{ steps.jsm.outputs.reporter }}
          AI_JSON:       ${{ steps.parse_ai.outputs.json }}
          AI_MD_CORE:    ${{ steps.sanitize_ai.outputs.ai_core }}
          SEV_LABEL:     ${{ steps.sev.outputs.label }}
        with:
          script: |
            const fs=require('fs');
            const aiJson=JSON.parse(process.env.AI_JSON||'{}');
            const desc=fs.readFileSync('description_fixed.html','utf8');
            const atts=fs.readFileSync('attachments.md','utf8');
            const aiMd=fs.readFileSync(process.env.AI_MD_CORE,'utf8');
            const userReq=fs.readFileSync('user_req_ck.md','utf8');
            const itReq=fs.readFileSync('it_req_ck.md','utf8');
            const userRec=fs.readFileSync('user_rec_ck.md','utf8');
            const itRec=fs.readFileSync('it_rec_ck.md','utf8');
            const sla=fs.readFileSync('sla.md','utf8');

            const head=[
              '### Origen: Jira Service Management (SD)',
              `- **Ticket:** [${process.env.ISSUE_KEY}](${process.env.JIRA_BASE_URL}/browse/${process.env.ISSUE_KEY})`,
              `- **Proyecto/Tipo:** ${process.env.PROJECT} / ${process.env.TYPE}`,
              `- **Prioridad (JSM):** ${process.env.PRIORITY}`,
              `- **Reportado por:** ${process.env.REPORTER}`,
              '',
              '### Descripcion (JSM renderizada)',
              `<details><summary>Ver</summary>\n\n${desc}\n\n</details>`,
              '',
              '### Adjuntos',
              atts,
              '',
              '---',
              '## Analisis de IA'
            ].join('\n');

            const reqs=[
              '## Requisitos adicionales para replicar',
              '### Usuarios (no tecnicos)',
              userReq,
              '',
              '### Equipo de TI',
              itReq
            ].join('\n');

            const recs=[
              '## Recomendaciones',
              '### Usuarios (no tecnicos)',
              userRec,
              '',
              '### Equipo de TI',
              itRec
            ].join('\n');

            const body=[head, aiMd, reqs, recs, sla].join('\n\n');

            // ----- Labels IA + SLA -----
            const allowed = new Set([
              'bug','documentation','duplicate','enhancement',
              'good first issue','help wanted','invalid','question','wontfix'
            ]);
            const want = Array.isArray(aiJson.labels) ? aiJson.labels.map(s=>String(s).trim()).filter(Boolean) : [];
            const {data: repoLabels}=await github.rest.issues.listLabelsForRepo({
              owner:context.repo.owner, repo:context.repo.repo, per_page:200
            });
            const existing = new Map(repoLabels.map(l=>[l.name.toLowerCase(), l.name]));

            // Base labels
            const finalLabels = new Set(['from-jsm','triage','agent-ready', process.env.SEV_LABEL]);

            // Crea labels faltantes SOLO si están en la lista blanca
            for (const l of want) {
              const lower=l.toLowerCase();
              if (existing.has(lower)) { finalLabels.add(existing.get(lower)); continue; }
              if (allowed.has(lower)) {
                try {
                  const created = await github.rest.issues.createLabel({
                    owner:context.repo.owner, repo:context.repo.repo,
                    name:l, color:'A3A3A3', description:'Auto-creado por IA (whitelist)'
                  });
                  finalLabels.add(created.data.name);
                } catch (e) { /* ignore */ }
              }
            }

            const create=await github.rest.issues.create({
              owner:context.repo.owner, repo:context.repo.repo,
              title:`[${process.env.ISSUE_KEY}] ${process.env.SUMMARY}`,
              body, labels:[...finalLabels].filter(Boolean)
            });
            core.setOutput('number', create.data.number);

      - name: JSM internal comment (full AI) - robust
        env:
          JIRA_EMAIL:  ${{ secrets.JIRA_EMAIL }}
          JIRA_API_TOKEN: ${{ secrets.JIRA_API_TOKEN }}
          ISSUE_KEY:   ${{ steps.key.outputs.issue_key }}
          AI_MD_FILE:  ${{ steps.sanitize_ai.outputs.ai_core }}
        run: |
          set -euo pipefail
          AUTH="$(printf "%s:%s" "$JIRA_EMAIL" "$JIRA_API_TOKEN" | base64 -w 0 2>/dev/null || printf "%s:%s" "$JIRA_EMAIL" "$JIRA_API_TOKEN" | base64)"
          MD_CONTENT="$(cat "$AI_MD_FILE")"
          BODY="$(jq -n --arg md "$MD_CONTENT" '{body:$md, public:false}')"
          CODE=$(curl -sS -o /tmp/jsm_resp.json -w "%{http_code}" -X POST \
            -H "Authorization: Basic $AUTH" -H "Accept: application/json" -H "Content-Type: application/json" \
            --data "$BODY" "$JIRA_BASE_URL/rest/servicedeskapi/request/${ISSUE_KEY}/comment")
          if [ "$CODE" != "201" ] && [ "$CODE" != "200" ]; then
            echo "No se pudo publicar el comentario interno en JSM (HTTP $CODE):"
            cat /tmp/jsm_resp.json || true
          fi

      - name: Copilot quick-link comment
        uses: actions/github-script@v7
        with:
          script: |
            const issueNumber = +'${{ steps.create_issue.outputs.number }}';
            const url = `https://github.com/${context.repo.owner}/${context.repo.repo}/issues/${issueNumber}`;
            const body = [
              '### Copilot (Coding Agent)',
              `➡️ [Asignar a Copilot](${url}) — abre el issue y usa el botón **Use Copilot** / **Assign to Copilot**.`,
              'El brief y contexto están listos en el cuerpo del issue.'
            ].join('\n');
            await github.rest.issues.createComment({
              owner: context.repo.owner, repo: context.repo.repo,
              issue_number: issueNumber, body
            });
