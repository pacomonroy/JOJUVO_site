name: "JSM SD â†’ GitHub Issue + AI Triage (agent-ready, net-aware, read-only)"

on:
  repository_dispatch:
    types: [jsm_ticket_created]
  workflow_dispatch:
    inputs:
      issue_key:
        description: "JSM key (e.g. SD-1)"
        required: false
        type: string

concurrency:
  group: jsm-${{ github.event.client_payload.issue_key || github.event.inputs.issue_key || 'manual' }}
  cancel-in-progress: false

permissions:
  contents: read
  issues: write
  models: read

env:
  TZ: America/Mexico_City
  JIRA_BASE_URL: https://appix.atlassian.net

jobs:
  ingest-triage:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: "Checkout (read-only)"
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          fetch-depth: 1

      - name: "Payload debug"
        uses: actions/github-script@v7
        with:
          script: |
            core.info(`event: ${context.eventName}`);
            core.info(JSON.stringify(context.payload, null, 2));

      - name: "Read JSM ticket"
        id: jsm
        shell: bash
        env:
          JIRA_EMAIL:     ${{ secrets.JIRA_EMAIL }}
          JIRA_API_TOKEN: ${{ secrets.JIRA_API_TOKEN }}
          ISSUE_KEY:      ${{ github.event.client_payload.issue_key }}
          INPUT_ISSUE_KEY: ${{ github.event.inputs.issue_key }}
        run: |
          set -euo pipefail
          ISSUE_KEY="${ISSUE_KEY:-${INPUT_ISSUE_KEY:-}}"
          test -n "${ISSUE_KEY:-}" || { echo "Missing issue_key"; exit 1; }

          AUTH="$(printf "%s:%s" "$JIRA_EMAIL" "$JIRA_API_TOKEN" | base64 -w 0 2>/dev/null || printf "%s:%s" "$JIRA_EMAIL" "$JIRA_API_TOKEN" | base64)"

          curl -fsS \
            -H "Authorization: Basic $AUTH" \
            -H "Accept: application/json" \
            "$JIRA_BASE_URL/rest/api/3/issue/$ISSUE_KEY?expand=renderedFields&fields=summary,description,priority,reporter,attachment,issuetype,project" \
            > issue.json

          jq -re '.fields' issue.json >/dev/null

          {
            echo "issue_key=$ISSUE_KEY"
            echo "summary=$(jq -r '.fields.summary' issue.json)"
            echo "priority=$(jq -r '.fields.priority.name // \"Unspecified\"' issue.json)"
            echo "reporter=$(jq -r '.fields.reporter.displayName // \"Unknown\"' issue.json)"
            echo "project=$(jq -r '.fields.project.key' issue.json)"
            echo "type=$(jq -r '.fields.issuetype.name' issue.json)"
          } >> "$GITHUB_OUTPUT"

          jq -r '.renderedFields.description // ""' issue.json > description.html
          jq -r '.fields.attachment // [] | .[] | [.filename,.content,.mimeType] | @tsv' issue.json > attachments.tsv || true

      - name: "Fix description (absolute links, no inline img)"
        run: |
          set -euo pipefail
          sed -E "s#(src|href)=\"\/#\\1=\"${JIRA_BASE_URL}/#g" description.html > description_abs.html
          perl -0777 -pe 's#<img[^>]+src="([^"]+)"[^>]*>#\[Imagen JSM\]\($1\)#gi' description_abs.html > description_fixed.html

      - name: "Install tools"
        run: |
          sudo apt-get update -y
          sudo apt-get install -y dnsutils tesseract-ocr

      - name: "Download image attachments + OCR"
        id: ocr
        shell: bash
        env:
          JIRA_EMAIL:     ${{ secrets.JIRA_EMAIL }}
          JIRA_API_TOKEN: ${{ secrets.JIRA_API_TOKEN }}
        run: |
          set -euo pipefail
          AUTH="$(printf "%s:%s" "$JIRA_EMAIL" "$JIRA_API_TOKEN" | base64 -w 0 2>/dev/null || printf "%s:%s" "$JIRA_EMAIL" "$JIRA_API_TOKEN" | base64)"
          mkdir -p attachments ocr
          : > ocr/ocr.txt
          while IFS=$'\t' read -r NAME URL MIME; do
            case "$MIME" in
              image/*)
                OUT="attachments/${NAME}"
                curl -fsS -H "Authorization: Basic $AUTH" -o "$OUT" "$URL" || continue
                tesseract "$OUT" "ocr/${NAME}" -l spa+eng --psm 6 >/dev/null 2>&1 || true
                [ -f "ocr/${NAME}.txt" ] && { echo "--- ${NAME} ---" >> ocr/ocr.txt; cat "ocr/${NAME}.txt" >> ocr/ocr.txt; echo >> ocr/ocr.txt; }
                ;;
            esac
          done < attachments.tsv
          if [ ! -s ocr/ocr.txt ]; then echo "No OCR text" > ocr/ocr.txt; fi
          echo "ocr_file=ocr/ocr.txt" >> "$GITHUB_OUTPUT"

      - name: "Detect hostname"
        id: host
        shell: bash
        env:
          SITE_URL: ${{ secrets.SITE_URL }}
        run: |
          set -euo pipefail
          PICK=""
          [ -n "${SITE_URL:-}" ] && PICK="$SITE_URL"
          [ -z "$PICK" ] && PICK="$(grep -Eo 'https?://[^ )"]+' -m1 ops/context.md || true)"
          [ -z "$PICK" ] && PICK="$(grep -RhoE 'https?://[a-zA-Z0-9.-]+\.[a-z]{2,}[^" ]*' --include='*.{ts,tsx,js,jsx,json,md,astro,php,html}' -m1 || true)"
          [ -z "$PICK" ] && PICK="$(grep -Eo 'https?://[^ )"]+' -m1 description_fixed.html || true)"
          [ -z "$PICK" ] && PICK="$(grep -Eo 'https?://[^ ]+' -m1 ocr/ocr.txt || true)"
          HOST="$(echo "$PICK" | sed -E 's#https?://##; s#/.*##; s/[^a-zA-Z0-9\.\-].*//')"
          [ -z "$HOST" ] && HOST="jojuvo.com"
          echo "host=$HOST" >> "$GITHUB_OUTPUT"
          echo "url_guess=$PICK" >> "$GITHUB_OUTPUT"

      - name: "Network diagnostics (DNS/TLS/HTTP)"
        id: net
        shell: bash
        env:
          HOST: ${{ steps.host.outputs.host }}
        run: |
          set -euo pipefail
          : > netdiag.md
          echo "## Network diagnostics for $HOST" >> netdiag.md
          echo "### DNS" >> netdiag.md
          { dig +short A "$HOST"; dig +short AAAA "$HOST"; } | sed 's/^/- /' >> netdiag.md || true
          echo -e "\n### TLS (dates, issuer, subject)" >> netdiag.md
          timeout 10 bash -lc 'echo | openssl s_client -servername "$HOST" -connect "$HOST:443" 2>/dev/null | openssl x509 -noout -dates -issuer -subject' \
            | sed 's/^/  /' >> netdiag.md || echo "  (TLS check failed)" >> netdiag.md
          echo -e "\n### HTTP HEAD timings" >> netdiag.md
          curl -I --silent --show-error --connect-timeout 8 --max-time 15 "https://$HOST/" -w "\ncode:%{http_code} ip:%{remote_ip} t_connect:%{time_connect}s t_ttfb:%{time_starttransfer}s\n" \
            -o >(tee headers.txt >/dev/null) >> netdiag.md || echo "Request failed (timeout/conn error)" >> netdiag.md
          if [ -f headers.txt ]; then
            echo -e "\n### Response headers (subset)" >> netdiag.md
            grep -E '^(server:|cf-|x-litespeed|x-cache|via:|date:|content-type:|strict-transport-security:)' -i headers.txt | sed 's/^/  /' >> netdiag.md || true
          fi

      - name: "Build attachment list (JSM links)"
        run: |
          set -euo pipefail
          if [ -s attachments.tsv ]; then
            while IFS=$'\t' read -r NAME URL MIME; do
              printf -- "- [%s](%s)\n" "$NAME" "$URL"
            done < attachments.tsv > attachments.md
          else
            printf "_Sin adjuntos_\n" > attachments.md
          fi

      - name: "Load ops context (ops/context.md)"
        run: |
          set -euo pipefail
          if [ -f "ops/context.md" ]; then
            cp ops/context.md ops_context.md
          else
            printf "%s\n" "No hay contexto adicional (ops/context.md ausente)." > ops_context.md
          fi

      - name: "Repo context (tree + keyword matches)"
        id: repocontext
        shell: bash
        env:
          SUMMARY: ${{ steps.jsm.outputs.summary }}
        run: |
          set -euo pipefail
          PLAIN_DESC="$(sed -E 's/<[^>]+>//g' description_fixed.html | tr -d '\r')"
          TOKENS="$(printf "%s\n%s\n" "${SUMMARY:-}" "${PLAIN_DESC:-}" | tr '[:upper:]' '[:lower:]' | tr -cs '[:alnum:]' '\n' | awk 'length>2' | sort -u | head -n 20 | paste -sd'|' -)"
          : "${TOKENS:=.}"
          echo "### Repo tree (top 200)" > repo_context.md
          (git ls-files 2>/dev/null || find . -type f) | head -n 200 >> repo_context.md
          echo -e "\n### Keyword pattern\n${TOKENS}\n" >> repo_context.md
          echo "### Matches (first 200 lines across source files)" >> repo_context.md
          find . -type d \( -name .git -o -name node_modules -o -name dist -o -name build \) -prune -o \
            -type f \( -name "*.js" -o -name "*.ts" -o -name "*.tsx" -o -name "*.jsx" -o -name "*.php" -o -name "*.html" -o -name "*.css" -o -name "*.scss" -o -name "*.vue" -o -name "*.json" -o -name "*.md" \) \
            -print0 | xargs -0 -I{} sh -c 'grep -n -i -E "$0" "{}" | head -n 3' "${TOKENS}" | head -n 200 >> repo_context.md || true
          {
            echo ""
            echo "### Project commands"
            if [ -f package.json ]; then
              echo "\`\`\`json"
              jq -r '.scripts // {}' package.json
              echo "\`\`\`"
            fi
          } >> repo_context.md

      - name: "Prepare prompt (with OCR + NetDiag)"
        id: prep
        shell: bash
        run: |
          set -euo pipefail
          {
            echo "### Descripcion (HTML)"; cat description_fixed.html
            echo; echo "### OCR de imagenes"; cat ocr/ocr.txt
            echo; echo "### Network diagnostics"; cat netdiag.md
            echo; echo "### Host detectado"; echo "${{ steps.host.outputs.host }} (origen: ${{ steps.host.outputs.url_guess || 'heuristica' }})"
            echo; echo "### Adjuntos"; cat attachments.md
            echo; echo "### Contexto operativo"; cat ops_context.md
            echo; echo "### Repo context"; cat repo_context.md
            echo; echo "### SLA window"; echo "L-V 09:00-18:00 (CDMX)."
            echo; echo "### Labels permitidas"; echo "bug, documentation, duplicate, enhancement, good first issue, help wanted, invalid, question, wontfix"
          } > prompt.md

      - name: "AI analysis (layered triage)"
        id: ai
        uses: actions/ai-inference@v1
        with:
          model: openai/gpt-4o-mini
          system-prompt: |
            Actua como ingeniero de soporte senior. Usa OCR, NetDiag y contexto del repo/hosting.
            Devuelve EXACTAMENTE en Markdown:
            ## Clasificacion por capa
            - Capa sospechosa: (Cliente/Red | DNS/CDN | WAF/Seguridad | Servidor/Hosting | Aplicacion/Codigo)
            - Evidencia clave (max 5 bullets)
            - Confianza (baja/media/alta)
            ## Posible causa
            ## Solucion potencial
            ## Requisitos adicionales para replicar
            - Usuarios (no tecnicos)
            - Equipo de TI
            ## Riesgos/Infra (WAF/VPN/Server)
            Al final agrega un bloque ```json``` con:
            {"layer":"Cliente/Red|DNS/CDN|WAF/Seguridad|Servidor/Hosting|Aplicacion/Codigo","cause":"...","solution":"...","replication_requirements_user":["..."],"replication_requirements_it":["..."],"risk_notes":"...","labels":["bug","question"],"confidence":"baja|media|alta"}
            Reglas: si hay ERR_CONNECTION_TIMED_OUT/NAME_NOT_RESOLVED o NetDiag muestra DNS vacio/TLS vencido/timeout, prioriza Cliente/Red, DNS/CDN o WAF/Seguridad sobre Aplicacion/Codigo.
          prompt-file: prompt.md
          max-tokens: 900

      - name: "Extract AI JSON"
        id: parse_ai
        shell: bash
        run: |
          set -euo pipefail
          awk '/```json/{flag=1;next}/```/{flag=0}flag' "${{ steps.ai.outputs.response-file }}" > ai.json || true
          jq -e . ai.json >/dev/null 2>&1 || echo '{}' > ai.json
          echo "json=$(cat ai.json | jq -c .)" >> "$GITHUB_OUTPUT"

      - name: "Build checklists from AI (user/nontech & IT)"
        id: ck
        shell: bash
        run: |
          set -euo pipefail
          # base from AI arrays
          jq -r '.replication_requirements_user // [] | .[] | "- [ ] " + .' ai.json > user_ck.md || echo > user_ck.md
          jq -r '.replication_requirements_it   // [] | .[] | "- [ ] " + .' ai.json > it_ck.md   || echo > it_ck.md
          # extra friendly checklist if Cliente/Red
          LAYER="$(jq -r '.layer // ""' ai.json)"
          if echo "$LAYER" | grep -qi "Cliente/Red"; then
            cat >> user_ck.md <<'MD'
- [ ] Probar sin VPN/Proxy y sin bloqueadores de anuncios
- [ ] Probar desde red movil (datos) o otra red WiFi
- [ ] Probar en modo incognito y otro navegador
- [ ] Captura de pantalla COMPLETA (incluye barra de direcciones y hora del sistema)
- [ ] Confirmar URL exacta y pasos previos al error
MD
          fi
          # defaults if empty
          [ -s user_ck.md ] || echo "- [ ] Screenshot de pantalla completa" > user_ck.md
          [ -s it_ck.md   ] || echo "- [ ] Confirmar si hay mantenimiento/implantacion en servidor o WAF" > it_ck.md

      - name: "Compute SLA (biz hours CDMX)"
        id: sla
        uses: actions/github-script@v7
        env:
          PRIORITY: ${{ steps.jsm.outputs.priority }}
          TZ: America/Mexico_City
        with:
          script: |
            function addBizHours(hours) {
              const tz = process.env.TZ || 'America/Mexico_City';
              const isBizDay = d => { const w = d.getDay(); return w >= 1 && w <= 5; };
              const start = new Date(new Date().toLocaleString('en-US', { timeZone: tz }));
              const setHour = (d, h) => { d.setHours(h, 0, 0, 0); return d; };
              let d = start;
              if (d.getHours() < 9) d = setHour(d, 9);
              if (d.getHours() >= 18) { do { d.setDate(d.getDate() + 1); } while (!isBizDay(d)); d = setHour(d, 9); }
              let remaining = hours;
              while (remaining > 0) {
                if (!isBizDay(d)) { do { d.setDate(d.getDate() + 1); } while (!isBizDay(d)); d = setHour(d, 9); continue; }
                const todayLeft = 18 - d.getHours();
                const step = Math.min(remaining, todayLeft);
                d.setHours(d.getHours() + step);
                remaining -= step;
                if (remaining > 0) { do { d.setDate(d.getDate() + 1); } while (!isBizDay(d)); d = setHour(d, 9); }
              }
              return d;
            }
            const pri = (process.env.PRIORITY || '').toUpperCase();
            const map = { 'P1': { resp: 3, res: 5 }, 'P2': { resp: 6, res: 8 }, 'P3': { resp: 9, res: 27 } };
            const sev = pri.includes('CRIT') ? 'P1' : (pri.includes('ALTA') ? 'P2' : 'P3');
            const dl = map[sev];
            const respBy = addBizHours(dl.resp);
            const resoBy = addBizHours(dl.res);
            const fmt = d => new Intl.DateTimeFormat('es-MX', { timeZone: process.env.TZ, dateStyle: 'medium', timeStyle: 'short' }).format(d);
            core.setOutput('sev', `sev:${sev}`);
            core.setOutput('resp', fmt(respBy));
            core.setOutput('reso', fmt(resoBy));

      - name: "Create Issue with JSM + AI + Checklists + SLA"
        id: create_issue
        uses: actions/github-script@v7
        env:
          ISSUE_KEY:    ${{ steps.jsm.outputs.issue_key }}
          SUMMARY:      ${{ steps.jsm.outputs.summary }}
          PROJECT:      ${{ steps.jsm.outputs.project }}
          TYPE:         ${{ steps.jsm.outputs.type }}
          PRIORITY:     ${{ steps.jsm.outputs.priority }}
          REPORTER:     ${{ steps.jsm.outputs.reporter }}
          SEV_LABEL:    ${{ steps.sla.outputs.sev }}
          RESP_DEADLINE:${{ steps.sla.outputs.resp }}
          RESO_DEADLINE:${{ steps.sla.outputs.reso }}
          AI_JSON:      ${{ steps.parse_ai.outputs.json }}
        with:
          script: |
            const fs = require('fs');
            const descHtml = fs.readFileSync('description_fixed.html','utf8');
            const atts = fs.readFileSync('attachments.md','utf8');
            const aiMd = fs.readFileSync(process.env.GITHUB_WORKSPACE + '/'+ process.env['GITHUB_ACTION_PATH'] ?? '', 'utf8'); // not used
            const aiMdFile = process.env['GITHUB_STEP_SUMMARY']; // not used
            const aiMdBody = fs.readFileSync(process.env['GITHUB_WORKSPACE'] + '/'+ 'prompt.md' , 'utf8'); // not used
            const aiRendered = fs.readFileSync(`${process.env.GITHUB_WORKSPACE}/` + `${process.env['GITHUB_ACTION']?'':''}`, 'utf8'); // placeholder
            const aiOut = fs.readFileSync(process.env.AI_RESPONSE_FILE || (process.env.AI_MD_FILE || ''), 'utf8', (e)=>''); // compat
            const aiFile = process.env.AI_MD_FILE || `${process.env.GITHUB_WORKSPACE}/_ai.md`;
            let aiMdText = '';
            try { aiMdText = fs.readFileSync(process.env.AI_MD_FILE,'utf8'); } catch(e) { aiMdText = fs.readFileSync(`${process.env.GITHUB_WORKSPACE}/_temp_ai_response.md`,'utf8', (e)=>''); }
            if (!aiMdText) { aiMdText = fs.readFileSync(`${process.env.GITHUB_WORKSPACE}/../_actions_output/response.md`,'utf8', (e)=>''); }
            // fallback: read from action output path
            try { aiMdText = fs.readFileSync(process.env['ACTIONS_AI_INFERENCE_RESPONSE_FILE'] || '', 'utf8'); } catch(e) {}

            // Read checklists
            const userCk = fs.readFileSync('user_ck.md','utf8');
            const itCk   = fs.readFileSync('it_ck.md','utf8');

            // Compose Issue body
            const head = [
              '### Origen: Jira Service Management (SD)',
              `- **Ticket:** [${process.env.ISSUE_KEY}](${process.env.JIRA_BASE_URL}/browse/${process.env.ISSUE_KEY})`,
              `- **Proyecto/Tipo:** ${process.env.PROJECT} / ${process.env.TYPE}`,
              `- **Prioridad (JSM):** ${process.env.PRIORITY}`,
              `- **Reportado por:** ${process.env.REPORTER}`,
              '',
              '### Descripcion (JSM renderizada)',
              `<details><summary>Ver</summary>\n\n${descHtml}\n\n</details>`,
              '',
              '### Adjuntos',
              atts,
              '',
              '---',
              '## Analisis de IA',
            ].join('\n');

            const aiMd = fs.readFileSync(process.env.AI_MD_FILE,'utf8');
            const aiJson = JSON.parse(process.env.AI_JSON || '{}');

            const reqs = [
              '## Requisitos adicionales para replicar',
              '### Para usuarios (no tecnicos)',
              userCk,
              '',
              '### Para equipo de TI',
              itCk,
              '',
              '---',
              '## SLA (horas habiles CDMX)',
              `- Respuesta: **${process.env.RESP_DEADLINE}**`,
              `- Resolucion: **${process.env.RESO_DEADLINE}**`
            ].join('\n');

            // Labels: from-jsm, triage, agent-ready, sev:P?, + AI labels que existan
            const wanted = Array.isArray(aiJson.labels) ? aiJson.labels : [];
            const { data: repoLabels } = await github.rest.issues.listLabelsForRepo({ owner: context.repo.owner, repo: context.repo.repo, per_page: 200 });
            const exist = new Set(repoLabels.map(l => l.name.toLowerCase()));
            const toApply = [...new Set(wanted.map(s => String(s).trim()))].filter(Boolean).filter(s => exist.has(s.toLowerCase()));

            const create = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `[${process.env.ISSUE_KEY}] ${process.env.SUMMARY}`,
              body: [head, aiMd, reqs].join('\n\n'),
              labels: ['from-jsm','triage','agent-ready', process.env.SEV_LABEL, ...toApply]
            });
            core.setOutput('number', create.data.number);
            core.setOutput('layer', aiJson.layer || '');

      - name: "JSM internal comment (full AI)"
        shell: bash
        env:
          JIRA_EMAIL:     ${{ secrets.JIRA_EMAIL }}
          JIRA_API_TOKEN: ${{ secrets.JIRA_API_TOKEN }}
          ISSUE_KEY:      ${{ steps.jsm.outputs.issue_key }}
        run: |
          set -euo pipefail
          AUTH="$(printf "%s:%s" "$JIRA_EMAIL" "$JIRA_API_TOKEN" | base64 -w 0 2>/dev/null || printf "%s:%s" "$JIRA_EMAIL" "$JIRA_API_TOKEN" | base64)"
          MD="$(sed 's/\\/\\\\/g; s/"/\\"/g' "${{ steps.ai.outputs.response-file }}")"
          BODY="$(jq -n --arg md "$MD" '{body:$md, public:false}')"
          curl -fsS -X POST -H "Authorization: Basic $AUTH" -H "Content-Type: application/json" --data "$BODY" \
            "$JIRA_BASE_URL/rest/servicedeskapi/request/${ISSUE_KEY}/comment" >/dev/null

      - name: "JSM public comment (user checklist if Cliente/Red)"
        shell: bash
        env:
          JIRA_EMAIL:     ${{ secrets.JIRA_EMAIL }}
          JIRA_API_TOKEN: ${{ secrets.JIRA_API_TOKEN }}
          ISSUE_KEY:      ${{ steps.jsm.outputs.issue_key }}
          LAYER:          ${{ steps.create_issue.outputs.layer }}
        run: |
          set -euo pipefail
          if echo "${LAYER:-}" | grep -qi "Cliente/Red"; then
            AUTH="$(printf "%s:%s" "$JIRA_EMAIL" "$JIRA_API_TOKEN" | base64 -w 0 2>/dev/null || printf "%s:%s" "$JIRA_EMAIL" "$JIRA_API_TOKEN" | base64)"
            BODY="$(jq -n --arg md "$(cat user_ck.md)" '{body:$md, public:true}')"
            curl -fsS -X POST -H "Authorization: Basic $AUTH" -H "Content-Type: application/json" --data "$BODY" \
              "$JIRA_BASE_URL/rest/servicedeskapi/request/${ISSUE_KEY}/comment" >/dev/null || true
          fi

      - name: "Agent-Ready brief"
        uses: actions/github-script@v7
        env:
          ISSUE_NUMBER: ${{ steps.create_issue.outputs.number }}
        with:
          script: |
            const fs = require('fs');
            const repoCtx = fs.readFileSync('repo_context.md','utf8');
            const body = [
              '> ### Agent-Ready Brief',
              '',
              '**Constraints**',
              '- Do not push to default branch. Open a PR with a clear plan.',
              '- Keep changes minimal and scoped.',
              '- No external network calls except allowed registries.',
              '- Respect Hostinger/LSWS, ModSecurity/WAF and caching rules (ops/context.md).',
              '',
              '**Repo context (summary)**',
              '<details><summary>Open</summary>',
              '',
              repoCtx,
              '',
              '</details>'
            ].join('\n');
            await github.rest.issues.createComment({ owner: context.repo.owner, repo: context.repo.repo, issue_number: Number(process.env.ISSUE_NUMBER), body });
